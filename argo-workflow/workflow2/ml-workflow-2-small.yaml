apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: llm-train
spec:
  entrypoint: train-and-predict
  arguments:
  parameters:
    - name: model-name
      value: sshleifer/tiny-gpt2 # or sshleifer/tiny-gpt2 for smaller model.
  volumes:
    - name: shared-data
      persistentVolumeClaim:
        claimName: model-pvc
  templates:
    - name: train-and-predict
      dag:
        tasks:
          - name: train
            template: train-model
            parameters:
              - name: model-name
                value: "{{workflow.parameters.model-name}}"

          - name: predict
            dependencies: [train]
            template: run-inference

    - name: train-model
      container:
        image: private.registry.com:31445/lightweight-llm-trainer:latest
        args: ["train_model_small.py", "{{inputs.parameters.model-name}}"]
        volumeMounts:
          - name: shared-data
            mountPath: /mnt/output
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        nodeSelector:
          kubernetes.io/hostname: "ubuntu02"

    - name: run-inference
      container:
        image: private.registry.com:31445/lightweight-llm-trainer:latest
        command: [python]
        args: ["predict_model_small.py"]
        volumeMounts:
          - name: shared-data
            mountPath: /mnt/output
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        nodeSelector:
          kubernetes.io/hostname: "ubuntu02"
